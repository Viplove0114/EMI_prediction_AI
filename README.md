EMIPredict AI - Intelligent Financial Risk Assessment Platform

This project is a comprehensive, end-to-end financial risk assessment platform built with Streamlit and MLflow. It solves a dual machine learning problem:

Classification: Predicts a customer's eligibility for an EMI (Eligible, High_Risk, Not_Eligible).

Regression: Predicts the maximum safe monthly EMI amount a customer can afford.

The application is built around a multi-page Streamlit dashboard that allows for data exploration, full model retraining, and live predictions.

ğŸš€ Key Features

Multi-Page Streamlit App: A clean, interactive UI for all project stakeholders.

ğŸ“Š Data Explorer: An EDA dashboard to visualize feature distributions and correlations.

ğŸš€ Model Training Pipeline: A one-click button to preprocess 400,000 records, train 6 different ML models, and log all results to MLflow.

ğŸ”® Live Prediction: A real-time prediction form that uses the best-performing models to assess new applicants instantly.

ğŸ¤– MLflow Integration: Complete experiment tracking for all models, including parameters, metrics, and model artifact registration.

Problem Statement

In the FinTech and Banking domain, many people struggle to pay EMIs due to poor financial planning and inadequate risk assessment. This project aims to solve this critical issue by providing data-driven insights for better loan decisions. The platform automates loan approval processes, reduces manual underwriting time, and provides a data-driven framework for risk assessment.

ğŸ›ï¸ Application Architecture & Data Flow

The application follows a modular structure:

emi_prediction_dataset.csv: The raw dataset of 400,000+ financial records.

utils.py: A central module containing all helper functions for:

Data Loading (load_data)

Data Cleaning (clean_data)

Feature Engineering (engineer_features)

Metric Evaluation (eval_..._metrics)

Prediction Preprocessing (preprocess_for_prediction)

app.py: The main landing page for the Streamlit application.

pages/: The directory containing all other app pages:

1_Data_Explorer.py: Loads and visualizes the clean data.

2_Model_Training.py: Runs the entire E2E training pipeline, saving artifacts (.joblib, .txt) and logging to MLflow.

3_Live_Prediction.py: Loads the saved artifacts and the "best" models from the MLflow Model Registry to perform live predictions.

mlruns/ (Generated by MLflow): The local directory where all MLflow experiment data, metrics, and model artifacts are stored.

ğŸ“ˆ Model Performance

All models are trained on a 70% split and evaluated on a 15% validation split. The best-performing models (XGBoost) are registered and used for the live prediction page.

After running the training pipeline, get the values from your MLflow UI (mlflow ui) and update the tables below.

Classification Model Comparison

Model

val_accuracy

val_precision_macro

val_recall_macro

val_f1_macro

val_roc_auc_macro

LogisticRegression

0.8989295125164

0.6280991852

0.5971680607

0.585490405

0.9370074925

RandomForestClassifier

0.922035573253

0.6042311760

0.6148864309

0.6091905124

0.9579005947

XGBoostClassifier

0.950658761524

0.8481546792

0.6654833784

0.6564675771

0.9858466349

Regression Model Comparison

Model

val_rmse

val_mae

val_r2

val_mape

LinearRegression

4131.790669

2953.203603

0.717817244

1.895492555

RandomForestRegressor

1521.983560

765.7537427

0.961711022

0.150784694

XGBoostRegressor

996.5985969

475.647648

0.983582977

0.188694153

ğŸ› ï¸ How to Run This Project

Follow these steps to set up and run the application on your local machine.

1. Setup

Clone the repository (or download the files) to your local machine.

Create a virtual environment:

python -m venv venv


Activate the virtual environment:

On Windows:

.\venv\Scripts\activate


On macOS/Linux:

source venv/bin/activate


Install all required libraries:

pip install -r requirements.txt


2. Run the Application

This is a two-part process: you must run the MLflow UI and the Streamlit App in separate terminals.

Terminal 1: Start the MLflow UI

In your activated terminal, run:

mlflow ui


Open your browser and go to http://127.0.0.1:5000 to view the MLflow dashboard.

Terminal 2: Start the Streamlit App

In a second activated terminal, run:

streamlit run app.py


If this fails due to environment issues, use the more explicit command:

python -m streamlit run app.py


Your browser should automatically open to the Streamlit app.

3. Application Workflow

Train Models: Once the app is running, navigate to the ğŸš€ Model Training page from the sidebar.

Click the ğŸš€ Start Full Training Pipeline button. This will take several minutes. It trains all 6 models, saves the scaler and encoder, and logs everything to MLflow.

Check MLflow: Go back to your MLflow UI (http://127.0.0.1:5000) and refresh. You will see all the new runs (e.g., XGBoostClassifier, RandomForestRegressor) with their metrics.

Get Live Predictions: Navigate to the ğŸ”® Live Prediction page. The app will automatically load the best models (XGBoostClassifier, XGBoostRegressor) from MLflow.

Fill out the form and click "Predict" to see the results.

ğŸ“‚ Project File Structure

EMIPredict_Al/
â”œâ”€â”€ .venv/                   # Virtual Environment
â”œâ”€â”€ mlruns/                  # MLflow Experiment Data (auto-generated)
â”œâ”€â”€ pages/                   # Streamlit pages
â”‚   â”œâ”€â”€ 1_Data_Explorer.py
â”‚   â”œâ”€â”€ 2_Model_Training.py
â”‚   â””â”€â”€ 3_Live_Prediction.py
â”œâ”€â”€ app.py                   # Main Streamlit app file (Home Page)
â”œâ”€â”€ utils.py                 # All helper functions (processing, training)
â”œâ”€â”€ emi_prediction_dataset.csv # The raw dataset
â”œâ”€â”€ requirements.txt         # All Python dependencies
â”œâ”€â”€ standard_scaler.joblib   # (Generated by training page)
â”œâ”€â”€ label_encoder.joblib     # (Generated by training page)
â””â”€â”€ feature_names.txt        # (Generated by training page)


ğŸ’» Tech Stack

Python 3.10+

Streamlit: For the interactive web application and UI.

Pandas: For data loading, manipulation, and cleaning.

Scikit-learn: For data preprocessing (StandardScaler, LabelEncoder) and baseline models (Logistic/Linear Regression).

XGBoost: For advanced, high-performance gradient-boosted models.

MLflow: For end-to-end experiment tracking, metric logging, and model registry.

Matplotlib & Seaborn: For visualizations in the Data Explorer.

Joblib: For saving and loading local artifacts (scaler, encoder).